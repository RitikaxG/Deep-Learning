{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0aaa3a2-96f8-4d92-894b-4f0f0aa3b40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0baa982f-facf-47b6-946b-64310dc5db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd45a07f-5244-4e84-8206-7e66db3c8c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test = ['nice movie indeed','I love python programming']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "text_preprocessed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f982eb30-78cd-4dbc-bec6-2ae04ed2197a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessed['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b144a146-e11b-4ba0-9cd4-09b7d37457cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  3835,  3185,  5262,   102,     0],\n",
       "        [  101,  1045,  2293, 18750,  4730,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize Text : Splitting text into individual tokens or subwords that BERT can understand\n",
    "text = ['nice movie indeed','I love python programming']\n",
    "tokens = tokenizer(text,padding=True, truncation=True, return_tensors='pt')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad9dd166-1b63-4efd-aa93-06eb9d6c57d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessed['attention_mask']\n",
    "\n",
    "#CLS nice movie indeed SEP : Therefore, 5 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d2dfa22-be5d-41e7-8575-b215ed85c669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessed['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd74fa80-d247-4202-a255-866e374decca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[101, 3835, 3185, 5262, 102], [101, 1045, 2293, 18750, 4730, 102]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessed['input_ids'] # 101: Fixed for CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80cc05c5-dd20-4d9f-8082-c7dc88cfd521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokens)\n",
    "\n",
    "hidden_states = outputs.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4aaf624f-5423-406e-9688-375025ea3fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.2337e-02,  8.5656e-02,  1.4587e-01,  ..., -9.7190e-02,\n",
       "           8.7726e-02,  7.7437e-02],\n",
       "         [ 1.7791e-01, -1.8862e-01,  5.0574e-01,  ..., -5.9180e-02,\n",
       "           3.2590e-01, -1.5619e-01],\n",
       "         [ 1.8731e-01, -4.3433e-01, -4.8739e-01,  ..., -1.5537e-01,\n",
       "           9.5849e-04, -2.4511e-01],\n",
       "         [ 1.7885e-01,  1.0839e-02,  3.4929e-01,  ...,  3.8419e-01,\n",
       "           3.4832e-01, -6.2698e-01],\n",
       "         [ 8.0329e-01,  1.1814e-01, -1.6948e-01,  ...,  2.4301e-01,\n",
       "          -6.7876e-01, -1.4544e-01],\n",
       "         [-1.9695e-02, -4.9773e-02,  3.6832e-01,  ...,  1.2161e-01,\n",
       "           2.5756e-01, -1.6424e-02]],\n",
       "\n",
       "        [[-8.1948e-02,  3.6322e-01, -2.1090e-01,  ..., -1.7285e-01,\n",
       "           1.6176e-01,  6.7104e-01],\n",
       "         [ 2.7789e-01,  4.3794e-01, -3.5919e-01,  ..., -4.4613e-02,\n",
       "           3.8115e-01,  5.8834e-01],\n",
       "         [ 1.2019e+00,  1.0733e+00,  4.8757e-01,  ...,  2.5087e-01,\n",
       "           4.0774e-01,  4.0351e-01],\n",
       "         [ 1.2860e-01,  8.9734e-01, -1.4539e-01,  ..., -2.7138e-01,\n",
       "          -1.3397e-01, -3.7797e-01],\n",
       "         [ 1.9287e-01, -1.7495e-01,  1.5506e-01,  ...,  2.6240e-01,\n",
       "          -1.3813e-03,  1.8498e-01],\n",
       "         [ 6.0107e-01,  2.9601e-01, -7.8309e-02,  ...,  2.5268e-01,\n",
       "          -6.1351e-01, -1.0624e-01]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtain BERT Embeddings : BERT provides contextual embeddings for each token in input sequence\n",
    "outputs = model(**tokens)\n",
    "embeddings = outputs.last_hidden_state\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc16b701-2dbf-4013-9041-152f8f5107b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00adf40d-1869-486a-ae8b-305c52960e98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
