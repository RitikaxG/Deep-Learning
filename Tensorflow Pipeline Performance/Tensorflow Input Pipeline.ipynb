{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0978391-73df-4c74-b7bd-9e63e8a36c79",
   "metadata": {},
   "source": [
    "##### Streming Approach: Loading dataset into batches\n",
    "* tf.data.Dataset: Helps to build tensorflow input pipeline\n",
    "* tf_dataset.filter(filter_func): To detect if dataset is blurry or not\n",
    "  ##### How to apply all filters at once\n",
    "* tf_dataset = tf.data.Dataset.list_files('images/*').map(process_img).filter(filter_func).map(lambda x:x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a48673b2-61be-416b-a3a5-ef5078c5f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdf2e3fa-fd5a-452e-bfaa-c4e09955e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales_numbers = [21,22, -100, 31, -1, 32, 34, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cfef489-fd01-4bc0-95ce-8787d57d6137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ba24303-9748-4ffa-91b3-4ecf72fa1ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-100\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd58b40d-7b92-4146-b487-065434eb8ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-100\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.take(3):\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e6c5dbf-a36b-4f4a-a982-ce74daf550a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "31\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "#Filtering datapoints : \n",
    "tf_dataset = tf_dataset.filter(lambda x:x>0)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b26a6cfa-58ee-4e1d-9dda-f4788de46bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1743\n",
      "1826\n",
      "2573\n",
      "2656\n",
      "2822\n",
      "2573\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.map(lambda x: x*83)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00520eb3-fae1-42c7-97aa-ffb248962e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1743\n",
      "2573\n",
      "1826\n",
      "2656\n",
      "2573\n",
      "2822\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.shuffle(2)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5b43e8a-b081-4096-9dd5-12f2d2b0bb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1743 2573]\n",
      "[1826 2822]\n",
      "[2656 2573]\n"
     ]
    }
   ],
   "source": [
    "#Creating batches\n",
    "for sales_batch in tf_dataset.batch(2):\n",
    "    print(sales_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bff3916-c69c-4b57-9802-5ac9151080a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1760 2480]\n",
      " [2560 2720]]\n",
      "[[1680 2480]]\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "#Filtering, Maping, Shuffling, Batching\n",
    "tf_dataset = tf_dataset.filter(lambda x: x>0).map(lambda y: y*80).shuffle(2).batch(2)\n",
    "for sales_batch in tf_dataset.batch(2):\n",
    "    print(sales_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a94d94e-6031-4361-a4a7-264a19e9037e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images/cat/00tb-cats1-videoSixteenByNineJumbo1600.jpg'\n",
      "b'images/cat/07CAT-STRIPES-mediumSquareAt3X-v2.jpg'\n",
      "b'images/cat/1200px-RedCat_8727.jpg'\n"
     ]
    }
   ],
   "source": [
    "images_ds = tf.data.Dataset.list_files('images/*/*', shuffle=False)\n",
    "#Stored the image path\n",
    "for files in images_ds.take(3):\n",
    "    print(files.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2af653c7-5536-499d-a252-f724f783a382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images/dog/Cavalier-King-Charles-Spaniel-laying-down-indoors.jpg'\n",
      "b'images/cat/Cat-andriyko-podilnyk-RCfi7vgJjUY-unsplash_1659328989095_1659328998370_1659328998370.jpg'\n",
      "b'images/dog/best-dog-breeds-for-seniors-4138298-hero-a02732418cd343eb89164c4230e0b574.jpg'\n"
     ]
    }
   ],
   "source": [
    "#Shuffling image\n",
    "#200 : Buffer size\n",
    "images_ds = images_ds.shuffle(200)\n",
    "#Stored the image path\n",
    "for files in images_ds.take(3):\n",
    "    print(files.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5272481e-b05d-43d6-a00f-e04167388970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['cat','dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8972b651-1b90-4b92-945c-b5fa89de4f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(images_ds)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4936790a-2bcb-47f7-93ec-d3d00ab365d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "train_size = int(image_count*0.8)\n",
    "\n",
    "train_ds = images_ds.take(train_size) #Will take 80% of dataset\n",
    "test_ds = images_ds.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ee92b46-e050-48e1-9aa7-f1c63792aac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a34bff9-0795-4095-8ea6-b73f989e44ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a74f2b4-4ff6-4400-8272-1632371ffb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retrieving label from the string\n",
    "s= \"b'images/dog/best-dog-breeds-for-seniors-4138298-hero-a02732418cd343eb89164c4230e0b574.jpg\"\n",
    "s.split('/')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9697eef1-bc51-4ab7-9cb3-9f3cceb72e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since file path is a tensor object we use spatial function\n",
    "def get_label(file_path):\n",
    "    import os\n",
    "    return tf.strings.split(file_path, os.path.sep)[-2]   #os seperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01d89010-5218-41d5-9d0a-87a5703aab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting label as well as the image\n",
    "def process_image(file_path):\n",
    "    label = get_label(file_path)\n",
    "    #Reading the file\n",
    "    img = tf.io.read_file(file_path)\n",
    "    #Decoding jpeg image\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    #Resizing the image\n",
    "    img = tf.image.resize(img, [128,128])\n",
    "\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2f7cfd8-8849-4258-bd83-e455718b809d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images/cat/red-white-cat-i-white-studio_155003-13189.jpg'\n",
      "b'images/cat/255883.jpg'\n",
      "b'images/cat/sick_cat_1660402138551_1660402151976_1660402151976.jpg'\n",
      "b'images/cat/maxresdefault (1).jpg'\n"
     ]
    }
   ],
   "source": [
    "for t in train_ds.take(4):\n",
    "     print(t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b487880-4cb5-4e85-9653-6736804c0ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: tf.Tensor(\n",
      "[[[163.       188.       122.      ]\n",
      "  [164.       189.       123.      ]\n",
      "  [164.       189.       123.      ]\n",
      "  ...\n",
      "  [162.       185.       115.      ]\n",
      "  [162.       185.       117.      ]\n",
      "  [161.       184.       116.      ]]\n",
      "\n",
      " [[164.       189.       123.      ]\n",
      "  [164.       189.       123.      ]\n",
      "  [165.       190.       124.      ]\n",
      "  ...\n",
      "  [162.       185.       115.      ]\n",
      "  [162.       185.       117.      ]\n",
      "  [162.       185.       117.      ]]\n",
      "\n",
      " [[165.       190.       124.      ]\n",
      "  [165.       190.       124.      ]\n",
      "  [166.       191.       125.      ]\n",
      "  ...\n",
      "  [160.       186.       113.      ]\n",
      "  [162.       185.       115.      ]\n",
      "  [162.       185.       115.      ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[114.50391  132.625     74.86719 ]\n",
      "  [ 97.19141  119.43359   55.67578 ]\n",
      "  [111.687744 123.92993   60.17212 ]\n",
      "  ...\n",
      "  [122.11743  120.05859   63.242188]\n",
      "  [141.95312  109.25      56.246094]\n",
      "  [145.98901   95.30859   48.429688]]\n",
      "\n",
      " [[105.72388  126.72388   70.635254]\n",
      "  [100.91016  126.91016   65.91016 ]\n",
      "  [108.875    129.88623   66.380615]\n",
      "  ...\n",
      "  [131.47266  131.47266   77.47266 ]\n",
      "  [123.       122.48389   66.24194 ]\n",
      "  [120.86719  109.6499    57.088623]]\n",
      "\n",
      " [[ 96.66968  121.66968   55.84546 ]\n",
      "  [104.73828  128.73828   68.38672 ]\n",
      "  [110.534424 136.35864   71.35864 ]\n",
      "  ...\n",
      "  [123.9375   132.7727    75.772705]\n",
      "  [118.76709  132.6394    75.72534 ]\n",
      "  [117.36328  124.01172   69.66016 ]]], shape=(128, 128, 3), dtype=float32)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "Image: tf.Tensor(\n",
      "[[[243.      243.      243.     ]\n",
      "  [243.      243.      243.     ]\n",
      "  [243.      243.      243.     ]\n",
      "  ...\n",
      "  [236.      236.      236.     ]\n",
      "  [234.38672 234.38672 234.38672]\n",
      "  [233.      233.      233.     ]]\n",
      "\n",
      " [[243.      243.      243.     ]\n",
      "  [243.      243.      243.     ]\n",
      "  [243.      243.      243.     ]\n",
      "  ...\n",
      "  [235.      235.      235.     ]\n",
      "  [234.38672 234.38672 234.38672]\n",
      "  [234.      234.      234.     ]]\n",
      "\n",
      " [[241.27344 241.27344 241.27344]\n",
      "  [241.27344 241.27344 241.27344]\n",
      "  [241.74173 241.74173 241.74173]\n",
      "  ...\n",
      "  [234.      234.      234.     ]\n",
      "  [233.      233.      233.     ]\n",
      "  [234.      234.      234.     ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[207.76181 207.76181 207.76181]\n",
      "  [208.72656 208.72656 208.72656]\n",
      "  [209.      209.      209.     ]\n",
      "  ...\n",
      "  [223.80515 223.80515 223.80515]\n",
      "  [224.11328 224.11328 224.11328]\n",
      "  [225.74219 225.74219 225.74219]]\n",
      "\n",
      " [[206.85709 206.85709 206.85709]\n",
      "  [207.83594 207.83594 207.83594]\n",
      "  [208.      208.      208.     ]\n",
      "  ...\n",
      "  [219.98074 219.98074 219.98074]\n",
      "  [221.38672 221.38672 221.38672]\n",
      "  [223.81479 223.81479 223.81479]]\n",
      "\n",
      " [[205.93826 205.93826 205.93826]\n",
      "  [205.89062 205.89062 205.89062]\n",
      "  [205.91006 205.91006 205.91006]\n",
      "  ...\n",
      "  [222.52707 222.52707 222.52707]\n",
      "  [222.68454 222.68454 222.68454]\n",
      "  [221.97351 221.97351 221.97351]]], shape=(128, 128, 3), dtype=float32)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "Image: tf.Tensor(\n",
      "[[[ 66.5      63.5      45.0625 ]\n",
      "  [ 57.34375  54.34375  39.34375]\n",
      "  [ 64.9375   61.9375   45.5    ]\n",
      "  ...\n",
      "  [ 75.75     72.75     54.875  ]\n",
      "  [ 67.875    65.875    43.4375 ]\n",
      "  [ 68.75     65.75     47.3125 ]]\n",
      "\n",
      " [[115.5     112.5      95.8125 ]\n",
      "  [119.      116.      101.     ]\n",
      "  [106.5     103.34375  88.8125 ]\n",
      "  ...\n",
      "  [ 55.4375   52.28125  37.90625]\n",
      "  [ 46.75     42.75     31.21875]\n",
      "  [ 52.375    48.375    37.6875 ]]\n",
      "\n",
      " [[ 13.       13.        5.     ]\n",
      "  [159.      156.      139.     ]\n",
      "  [ 15.59375  15.59375   7.59375]\n",
      "  ...\n",
      "  [ 19.1875   19.1875    9.1875 ]\n",
      "  [ 18.1875   20.1875    9.1875 ]\n",
      "  [ 18.78125  19.78125  11.78125]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[163.      164.      158.     ]\n",
      "  [155.1875  158.1875  151.1875 ]\n",
      "  [ 84.8125   79.8125   73.8125 ]\n",
      "  ...\n",
      "  [193.40625 194.40625 189.40625]\n",
      "  [193.59375 193.59375 193.59375]\n",
      "  [191.      192.      187.     ]]\n",
      "\n",
      " [[161.      162.      156.     ]\n",
      "  [137.15625 134.15625 125.15625]\n",
      "  [ 94.5      89.5      83.5    ]\n",
      "  ...\n",
      "  [196.375   197.375   192.375  ]\n",
      "  [193.6875  193.6875  193.6875 ]\n",
      "  [193.      194.      189.     ]]\n",
      "\n",
      " [[160.      161.      155.     ]\n",
      "  [ 81.40625  77.40625  65.40625]\n",
      "  [114.84375 107.84375  99.84375]\n",
      "  ...\n",
      "  [190.71875 194.71875 193.71875]\n",
      "  [192.71875 193.71875 188.71875]\n",
      "  [187.      192.      186.     ]]], shape=(128, 128, 3), dtype=float32)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for img, label in train_ds.map(process_image).take(3):\n",
    "    print(\"Image:\",img)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68a8f557-2b29-448f-9016-4a88c5b70170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    return image/255, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab147472-8d74-4aa2-b9b2-d664553411b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Image: [1.6381409e-10 1.6659650e-10 1.7123383e-10]\n",
      "****label: b'cat'\n",
      "****Image: [0.000000e+00 7.692916e-11 9.552924e-11]\n",
      "****label: b'cat'\n",
      "****Image: [1.3850436e-10 1.5334385e-10 9.4145282e-11]\n",
      "****label: b'dog'\n",
      "****Image: [8.2544686e-11 1.1964343e-10 1.6508937e-10]\n",
      "****label: b'dog'\n",
      "****Image: [0.000000e+00 0.000000e+00 1.854937e-12]\n",
      "****label: b'dog'\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(scale)\n",
    "for img, label in train_ds.take(5):\n",
    "    print(\"****Image:\",img.numpy()[0][0])\n",
    "    print(\"****label:\",label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1472702-ba87-4ed3-9d6b-660bebcfdb98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
